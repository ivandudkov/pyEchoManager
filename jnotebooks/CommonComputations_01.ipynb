{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba109bb-50c8-4cf5-b7e3-226a6659997a",
   "metadata": {},
   "source": [
    "SES .txt positions processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e9949c-5e9b-40a6-884b-8d5694c0c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if not '..' in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from utilities.file_ext_search import file_ext_search\n",
    "import os\n",
    "import os.path\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47436cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.pds files in directory:D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData\n",
      "Searching was unsuccessful. Trying to search in one directory up:\n",
      "D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\n",
      "Searching *.pds files in directory:D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData2\n",
      "Searching *.pds files in directory:D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData3\n"
     ]
    }
   ],
   "source": [
    "data1 = r'D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData'\n",
    "data2 = r'G:\\PDS Projects\\AkademikBorisPetrov_049\\LogData'\n",
    "data3 = r'F:\\ABP_49_part1\\PDS Projects\\AkademikBorisPetrov_049\\LogData'\n",
    "logdata2 = r'D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData2'\n",
    "logdata3 = r'D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData3'\n",
    "\n",
    "pds_files_1 = file_ext_search('.pds', data1)\n",
    "pds_files_2 = file_ext_search('.pds', logdata2)\n",
    "pds_files_3 = file_ext_search('.pds', logdata3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b7f11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 === 349\n"
     ]
    }
   ],
   "source": [
    "file_2GB = []\n",
    "count = 0\n",
    "for file in pds_files_2:\n",
    "    basename1 = os.path.basename(file)\n",
    "    \n",
    "    for file2 in pds_files_1:\n",
    "        basename2 = os.path.basename(file2)\n",
    "        if basename1 == basename2:\n",
    "            file_2GB.append(file2)\n",
    "    count += 1\n",
    "\n",
    "print(f'{count} === {len(file_2GB)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e363d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4822 === 4822\n"
     ]
    }
   ],
   "source": [
    "file_5GB = []\n",
    "count = 0\n",
    "\n",
    "for file in pds_files_3:\n",
    "    basename1 = os.path.basename(file)\n",
    "    count += 1\n",
    "    \n",
    "    for file2 in pds_files_1:\n",
    "        basename2 = os.path.basename(file2)\n",
    "        if basename1 == basename2:\n",
    "            file_5GB.append(file2)\n",
    "            \n",
    "print(f'{count} === {len(file_5GB)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdata2 = r'D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData2'\n",
    "\n",
    "for file in file_2GB:\n",
    "    shutil.move(file, logdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf71458",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdata3 = r'D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData3'\n",
    "\n",
    "for file in file_5GB:\n",
    "    shutil.move(file, logdata3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc13a986-b6e5-4765-9b20-3f2c4d6042b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_56_path = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-56_segy_converted'\n",
    "# ai_61_path = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_segy_converted'\n",
    "\n",
    "# ai_56_posfiles = find_ext('.txt', ai_56_path)\n",
    "# out_ai_61_merg_posfile = os.path.join(ai_56_path, 'ai_56_seg_positions.csv')\n",
    "\n",
    "# ai_61_posfiles = find_ext('.txt', ai_61_path)\n",
    "# out_ai_61_merg_posfile = os.path.join(ai_61_path, 'ai_61_seg_positions.csv')\n",
    "\n",
    "def process_posfiles(ses_posfiles, output_path_with_filename):\n",
    "    lf_files = []\n",
    "    hf_files = []\n",
    "    \n",
    "    filename_parts = os.path.splitext(output_path_with_filename)\n",
    "    print(filename_parts)\n",
    "    \n",
    "    \n",
    "    lf_path = filename_parts[0] + '_LF' + filename_parts[1]\n",
    "    hf_path = filename_parts[0] + '_HF' + filename_parts[1]\n",
    "    \n",
    "    for num, path in enumerate(ses_posfiles):\n",
    "        if 'motion' in path:\n",
    "            pass\n",
    "        else:\n",
    "            if 'RAW_LF' in str(path):\n",
    "                lf_files.append(path)\n",
    "            elif 'RAW_HF' in path:\n",
    "                hf_files.append(path)\n",
    "    \n",
    "    lf_files.sort()\n",
    "    hf_files.sort()\n",
    "                \n",
    "    def combine_files(filelist, out_filename):\n",
    "        file_names = []\n",
    "        easting = []\n",
    "        northing = []\n",
    "        datetimes = []\n",
    "        index = []\n",
    "        num = 0\n",
    "        for file in filelist:\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]\n",
    "\n",
    "            with open(file, 'r') as f1:\n",
    "                file_content = f1.read().splitlines()\n",
    "                for line in file_content:\n",
    "                    line_content = line.split(',')\n",
    "\n",
    "                    file_names.append(filename)\n",
    "                    easting.append(line_content[1])\n",
    "                    northing.append(line_content[2])\n",
    "\n",
    "                    datetime_obj = datetime.datetime.strptime(line_content[3],'%d.%m.%Y %H%M%S')\n",
    "                    datetimes.append(datetime_obj)\n",
    "                    index.append(num)\n",
    "                    num += 1\n",
    "            \n",
    "        with open(out_filename, 'w') as f2:\n",
    "            f2.write('num,fname,easting,northing,datetimeISO\\n')\n",
    "            for num in index:\n",
    "                f2.write(f'{num},{file_names[num]},{easting[num]},{northing[num]},{datetimes[num].isoformat()}\\n')\n",
    "            \n",
    "        print(f'Positions were merged in {out_filename} file')\n",
    "    \n",
    "        \n",
    "        \n",
    "    if len(lf_files) == 0:\n",
    "        print('There are no pos files for low frequency')\n",
    "    else:\n",
    "        combine_files(lf_files, lf_path)\n",
    "    if len(hf_files) == 0:\n",
    "        print('There are no pos files for high frequency')\n",
    "    else:\n",
    "        combine_files(hf_files, hf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965024a5-ea6e-4eea-94bf-f40a4c67b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.txt files in directory:D:\\bb_MyWorkProjects\\RNF2022\\AI-61_Gdan_converted\n",
      "('D:\\\\bb_MyWorkProjects\\\\RNF2022\\\\AI-61_Gdan_converted\\\\ai_61_Gdan_seg_positions', '.csv')\n",
      "Positions were merged in D:\\bb_MyWorkProjects\\RNF2022\\AI-61_Gdan_converted\\ai_61_Gdan_seg_positions_LF.csv file\n",
      "Positions were merged in D:\\bb_MyWorkProjects\\RNF2022\\AI-61_Gdan_converted\\ai_61_Gdan_seg_positions_HF.csv file\n"
     ]
    }
   ],
   "source": [
    "# ai_56_path = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-56_segy_converted'\n",
    "# ai_61_path = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_segy_converted'\n",
    "ai_61_Gdan_path = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_Gdan_converted'\n",
    "\n",
    "# ai_56_posfiles = find_ext('.txt', ai_56_path)\n",
    "# out_ai_56_merg_posfile = os.path.join(ai_56_path, 'ai_56_seg_positions.csv')\n",
    "\n",
    "# ai_61_posfiles = find_ext('.txt', ai_61_path)\n",
    "# out_ai_61_merg_posfile = os.path.join(ai_61_path, 'ai_61_seg_positions.csv')\n",
    "\n",
    "ai_61_Gdan_posfiles = find_ext('.txt', ai_61_Gdan_path)\n",
    "out_ai_61_Gdan_merg_posfile = os.path.join(ai_61_Gdan_path, 'ai_61_Gdan_seg_positions.csv')\n",
    "# process_posfiles(ai_56_posfiles,out_ai_56_merg_posfile)\n",
    "# process_posfiles(ai_61_posfiles,out_ai_61_merg_posfile)\n",
    "\n",
    "process_posfiles(ai_61_Gdan_posfiles, out_ai_61_Gdan_merg_posfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707a8be",
   "metadata": {},
   "source": [
    "SES 2000. Finding segy files using .raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8cec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.raw files in directory:D:\\bb_MyWorkProjects\\RNF2022\\AI-61_Gdan\n",
      "Searching *.sgy files in directory:D:\\bb_MyWorkProjects\\RNF2022\\AI-61_segy_converted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "from mycode.find_files_with_extension import find_file_with_extension\n",
    "\n",
    "path_raws = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_Gdan'\n",
    "path_segs = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_segy_converted'\n",
    "\n",
    "raws_files = find_file_with_extension('.raw', path_raws)\n",
    "segs_files = find_file_with_extension('.sgy', path_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a6216d-083f-46cd-8d4b-0d9c01e6e44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20220628', '094521']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(segs_files[0])\n",
    "os.path.splitext(os.path.basename(raws_files[0]))[0].split('_')\n",
    "for id_seg, seg_file in enumerate(segs_files):\n",
    "    for id_raw, raw_file in enumerate(raws_files):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc9f9ec9-f8d3-478f-8ad1-583183c2ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "# path - путь до .csv файла с названиями файлов и профилями\n",
    "# input_folder - папка с данными sgy\n",
    "path = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_SEB_segy_processing.csv'\n",
    "input_folder = r'D:\\bb_MyWorkProjects\\RNF2022\\AI-61_segy_converted'\n",
    "\n",
    "filenames = []\n",
    "profiles = []\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "    header = content[0].splitlines()[0].split(',')\n",
    "    filename_idx = 0\n",
    "    for field in header:\n",
    "        if field == 'fname' or field == 'Fname':\n",
    "            break\n",
    "        else:\n",
    "            filename_idx += 1\n",
    "\n",
    "    for idx, line in enumerate(content[1:]):\n",
    "        line_content = line.splitlines()[0].split(',')\n",
    "        filenames.append(line_content[filename_idx] + '.sgy')\n",
    "        profiles.append(line_content[-1])\n",
    "\n",
    "for profile, file in zip(profiles, filenames):\n",
    "    if profile:\n",
    "        filepath = os.path.join(input_folder,file)\n",
    "        output_path = os.path.join(input_folder,profile)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        shutil.copy(filepath, output_path)\n",
    "        print(filepath)\n",
    "        print(output_path)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91505862-4335-4b21-8e22-26e3e1a6a44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "542b0e3096725a2056735354746e8fb0274aaacae20b326a136954ba503430db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
