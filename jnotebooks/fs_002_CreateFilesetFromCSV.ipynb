{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "if not '..' in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from filemanager.fileset import PDSFileset\n",
    "from filemanager.file_ext_search import file_ext_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.csv files in directory:D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project\n",
      "0 D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project\\abp47_dtms.csv\n",
      "1 D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project\\abp48_dtms.csv\n",
      "2 D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project\\abp48_taranreg_fileset.csv\n",
      "3 D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project\\abp49_dtms.csv\n",
      "4 D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project\\abp49_taranreg_fileset.csv\n"
     ]
    }
   ],
   "source": [
    "# Create one fileset from a single csv file\n",
    "csv_fs = r'D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project'\n",
    "save_to = r'D:\\aa_yandexcloud\\bb_cloudDTMproc\\id01_taranproc\\gis_project'\n",
    "\n",
    "filesets = file_ext_search(extension='.csv', path=csv_fs)\n",
    "\n",
    "fs_list = []\n",
    "\n",
    "for num, fileset in enumerate(filesets):\n",
    "    print(f'{num} {fileset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_fileset = PDSFileset()\n",
    "pds_fileset._name = 'abp49_taranreg_fileset'\n",
    "\n",
    "pds_fileset.addfiles_fromlist(path=filesets[4])\n",
    "\n",
    "pds_fileset.savefileset(dirpath=save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\aa_yandexcloud\\aa_cloudmbesproceessing\\aa_abp49_processing\\filesets\\csv\\wreck_01_toclass.csv\n",
      "wreck_01_toclass\n",
      "10 of 10 files matched\n",
      "Copied 1 of 10 files\n",
      "Copied 2 of 10 files\n",
      "Copied 3 of 10 files\n",
      "Copied 4 of 10 files\n",
      "Copied 5 of 10 files\n",
      "Copied 6 of 10 files\n",
      "Copied 7 of 10 files\n",
      "Copied 8 of 10 files\n",
      "Copied 9 of 10 files\n",
      "Copied 10 of 10 files\n",
      "D:\\aa_yandexcloud\\aa_cloudmbesproceessing\\aa_abp49_processing\\filesets\\csv\\wreck_02_toclass.csv\n",
      "wreck_02_toclass\n",
      "23 of 23 files matched\n",
      "Copied 1 of 23 files\n",
      "Copied 2 of 23 files\n",
      "Copied 3 of 23 files\n",
      "Copied 4 of 23 files\n",
      "Copied 5 of 23 files\n",
      "Copied 6 of 23 files\n",
      "Copied 7 of 23 files\n",
      "Copied 8 of 23 files\n",
      "Copied 9 of 23 files\n",
      "Copied 10 of 23 files\n",
      "Copied 11 of 23 files\n",
      "Copied 12 of 23 files\n",
      "Copied 13 of 23 files\n",
      "Copied 14 of 23 files\n",
      "Copied 15 of 23 files\n",
      "Copied 16 of 23 files\n",
      "Copied 17 of 23 files\n",
      "Copied 18 of 23 files\n",
      "Copied 19 of 23 files\n",
      "Copied 20 of 23 files\n",
      "Copied 21 of 23 files\n",
      "Copied 22 of 23 files\n",
      "Copied 23 of 23 files\n"
     ]
    }
   ],
   "source": [
    "fs_list = []\n",
    "data1_copy_to = r'G:\\master_class_data\\data_1'\n",
    "data2_copy_to = r'G:\\master_class_data\\data_2'\n",
    "pds_logdata = r'D:\\zz_ABP49_PDSData\\PDS Projects\\AkademikBorisPetrov_049\\LogData'\n",
    "\n",
    "for num, fileset in enumerate(filesets[3:]):\n",
    "    print(fileset)\n",
    "    fileset_obj = PDSFileset()\n",
    "    fileset_obj.addfiles_fromlist(fileset)\n",
    "    filename = os.path.splitext(os.path.basename(fileset))[0]\n",
    "    fileset_obj._name = filename\n",
    "    print(fileset_obj.name)\n",
    "    fileset_obj.matchfiles(pds_logdata, verbose=True)\n",
    "\n",
    "    if num == 0:\n",
    "        fileset_obj.savefileset(dirpath=data1_copy_to)\n",
    "        fileset_obj.copyfiles(data1_copy_to, verbose=True)\n",
    "    elif num == 1:\n",
    "        fileset_obj.savefileset(dirpath=data2_copy_to)\n",
    "        fileset_obj.copyfiles(data2_copy_to, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abp49_id006_Poly02North_Po - 244\n",
      "abp49_id023_Hydro02_Pr - 66\n",
      "abp49_id038_NorthWestShallow_Tr - 51\n",
      "abp49_id008_TaranNS2_Po - 641\n",
      "abp49_id013_VSEGEI01to08_Po - 96\n",
      "abp49_id014_VSEGEI09_Pr - 39\n",
      "abp49_id007_TaranW_Po - 478\n",
      "abp49_id036_CameraSearch01_Po - 100\n",
      "abp49_id035_WestShallow_Tr - 103\n",
      "abp49_id010_Calib02_Po - 100\n",
      "abp49_id011_Wreck01BigShallow_Po - 147\n",
      "abp49_id002_TaranNS_Po - 682\n",
      "abp49_id039_NorthShallow_Tr - 129\n",
      "abp49_id001_TaranNN_Po - 124\n",
      "abp49_id037_CameraSearch02_Po - 68\n",
      "abp49_id016_Seism02_Pr - 19\n",
      "abp49_id024_Hydro03_Pr - 63\n",
      "abp49_id052_GdanGotlSillSouth_Tr - 20\n",
      "abp49_id019_Seism11_Pr - 29\n",
      "abp49_id012_KulikovoOP_Po - 280\n",
      "abp49_id040_SouthKosaShallow_Tr - 63\n",
      "abp49_id043_Wreck03Small_Po - 27\n",
      "abp49_id031_DNPoly_Po - 66\n",
      "abp49_id032_RBPoly_Po - 173\n",
      "abp49_id050_GdanskDeepNorth_Tr - 63\n",
      "abp49_id033_Channel_Tr - 94\n",
      "abp49_id034_SouthWestShallow_Tr - 105\n",
      "abp49_id045_SouthWestMed_Tr - 17\n",
      "abp49_id046_WestMed_Tr - 35\n",
      "abp49_id009_Calib01_Po - 24\n",
      "abp49_id022_Hydro01_Pr - 65\n",
      "abp49_id054_GdanGotlSillNorth_Tr - 87\n",
      "abp49_id005_ADCPRescure_Po - 22\n",
      "abp49_id047_NorthWestMed_Tr - 30\n",
      "abp49_id018_Seism04_Pr - 18\n",
      "abp49_id049_GdanskDeepSouth_Tr - 17\n",
      "abp49_id017_Seism03_Pr - 12\n",
      "abp49_id053_GdanGotlSillCenter_Tr - 13\n",
      "abp49_id020_Seism13_Pr - 37\n",
      "abp49_id021_Seism12_Pr - 31\n",
      "abp49_id044_Wreck04Small_Po - 11\n",
      "abp49_id025_Seism07_Pr - 1\n",
      "abp49_id026_Seism08_Pr - 1\n",
      "abp49_id027_Seism09_Pr - 2\n",
      "abp49_id028_Seism10_Pr - 1\n",
      "abp49_id041_NorthKosaShallow_Tr - 10\n",
      "abp49_id029_Dune3_Po - 15\n",
      "abp49_id030_Dune2_Po - 21\n",
      "abp49_id042_ReconNorthPoly_Po - 23\n",
      "abp49_id048_RybachyiMed_Tr - 10\n",
      "abp49_id004_Wreck04BigShip_Po - 98\n",
      "abp49_id051_GdanskDeepWest_Tr - 12\n",
      "abp49_id015_Seism01_Pr - 15\n",
      "abp49_id003_TaranSW_Po - 73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create multiple filesets from a single csv file\n",
    "csv_f = r'D:\\aa_yandexcloud\\aa_cloudmbesproceessing\\aa_abp49_processing\\filesets\\csv\\abp49_MBES_processing_filepaths.csv'\n",
    "save_to = r'D:\\aa_yandexcloud\\aa_cloudmbesproceessing\\aa_abp49_processing\\filesets\\sub'\n",
    "\n",
    "filesets = []\n",
    "\n",
    "filesets_dict = {}\n",
    "\n",
    "with open(csv_f, 'r') as csv_file:\n",
    "    file_content = csv_file.read().splitlines()\n",
    "\n",
    "    for num, line in enumerate(file_content[1:]):\n",
    "        line_content = line.split(',')\n",
    "        file_name = line_content[1]\n",
    "        fileset_name = line_content[9]\n",
    "\n",
    "        if fileset_name in filesets_dict.keys():\n",
    "            filesets_dict[fileset_name].append(file_name)\n",
    "        else:\n",
    "            filesets_dict[fileset_name] = []\n",
    "            filesets_dict[fileset_name].append(file_name)\n",
    "\n",
    "for key in filesets_dict.keys():\n",
    "    fileset_name = key\n",
    "    filenames = filesets_dict[key]\n",
    "\n",
    "    fileset = PDSFileset()\n",
    "    fileset.setname(fileset_name)\n",
    "    fileset.addfiles(filenames)\n",
    "    filesets.append(fileset)\n",
    "\n",
    "for fileset in filesets:\n",
    "    print(f'{fileset.name} - {len(fileset.files)}')\n",
    "    fileset.savefileset(dirpath=save_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe45e23cf9a5f980eae1e9eaca7f92a6ec17c53260c300cbc746fb4f3efe2e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
