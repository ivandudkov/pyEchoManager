{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, time, date\n",
    "from filemanager import file_ext_search as fes\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SegyPosFile:\n",
    "    name: str\n",
    "    path: str\n",
    "    fin_traceno: int = 0\n",
    "    datetime: list = field(default_factory=list)\n",
    "    traceno: list = field(default_factory=list)\n",
    "    cdp_x: list = field(default_factory=list)\n",
    "    cdp_x_smoothed: list = field(default_factory=list)\n",
    "    cdp_y_smoothed: list = field(default_factory=list)\n",
    "    cdp_x_cartesian_smoothed: list = field(default_factory=list)\n",
    "    cdp_y_cartesian_smoothed: list = field(default_factory=list)\n",
    "    cdp_y: list = field(default_factory=list)\n",
    "    year: list = field(default_factory=list)\n",
    "    day: list = field(default_factory=list)\n",
    "    hour: list = field(default_factory=list)\n",
    "    minute: list = field(default_factory=list)\n",
    "    second: list = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_segypos(pos_files, finedict, baddict, posobj_list, year, utm_coords=False):\n",
    "    for pos_file in pos_files:\n",
    "        segy_name = os.path.splitext(os.path.basename(pos_file))[0]\n",
    "        pos_obj = SegyPosFile(name=segy_name, path=pos_file)\n",
    "        \n",
    "        number = 0\n",
    "        has_error = False\n",
    "        was_before = False\n",
    "        \n",
    "        with open(pos_file, 'r') as file1:\n",
    "            file_content = file1.read().splitlines()\n",
    "            \n",
    "            for line in file_content[1:]:\n",
    "                line_content = line.split()\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    if utm_coords:\n",
    "                        if int(line_content[3]) != year:\n",
    "                            raise RuntimeError('BadYear')\n",
    "                        \n",
    "                        elif int(int(line_content[4])) > 370 and int(line_content[4]) < 0:\n",
    "                            raise RuntimeError('BadDay')\n",
    "                        \n",
    "                        elif float(line_content[1]) < 50000 and float(line_content[1]) > 500000:\n",
    "                            raise RuntimeError('BadCDP_X')\n",
    "                        \n",
    "                        elif float(line_content[2]) < 200000 and float(line_content[2]) > 8000000:\n",
    "                            raise RuntimeError('BadCDP_Y')\n",
    "\n",
    "                    else:\n",
    "                        if int(line_content[3]) != year:\n",
    "                            raise RuntimeError('BadYear')\n",
    "                        \n",
    "                        elif int(int(line_content[4])) > 370 and int(line_content[4]) < 0:\n",
    "                            raise RuntimeError('BadDay')\n",
    "                        \n",
    "                        elif float(line_content[1]) < 15.0 and float(line_content[1]) > 50.0:\n",
    "                            raise RuntimeError('BadCDP_X')\n",
    "                        \n",
    "                        elif float(line_content[2]) < 30.0 and float(line_content[2]) > 70.0:\n",
    "                            raise RuntimeError('BadCDP_Y')\n",
    "                    \n",
    "                    ar = time(hour=int(line_content[5]),\n",
    "                            minute=int(line_content[6]), second=int(line_content[7]))\n",
    "                except:\n",
    "                    number += 1\n",
    "                    has_error = True\n",
    "                    if not was_before:\n",
    "                        baddict[segy_name] = pos_obj.traceno[-1]\n",
    "                        was_before = True\n",
    "                        \n",
    "                else:\n",
    "                    pos_obj.datetime.append(f'{line_content[3]}-{line_content[4]}T{line_content[5]}:{line_content[6]}:{line_content[7]}')\n",
    "                    pos_obj.traceno.append(int(line_content[0]))\n",
    "                    pos_obj.cdp_x.append(float(line_content[1]))\n",
    "                    pos_obj.cdp_y.append(float(line_content[2]))\n",
    "                    pos_obj.year.append(int(line_content[3]))\n",
    "                    pos_obj.day.append(int(line_content[4]))\n",
    "                    pos_obj.hour.append(int(line_content[5]))\n",
    "                    pos_obj.minute.append(int(line_content[6]))\n",
    "                    pos_obj.second.append(int(line_content[7]))\n",
    "                    \n",
    "            finedict[segy_name] = pos_obj.traceno[-1]\n",
    "            \n",
    "            if has_error:\n",
    "                print(f'Number of bad lines in {segy_name}: {number}')\n",
    "                \n",
    "            posobj_list.append(pos_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_track(pos_objs, transformer, window_length=201, smooth=True, utm_coords=False):\n",
    "    for segy_pos_obj in pos_objs:\n",
    "        window_length = window_length\n",
    "        file_length = len(segy_pos_obj.cdp_x)\n",
    "        \n",
    "        loop = True\n",
    "        while loop:\n",
    "            if window_length > file_length/4 and window_length > 41:\n",
    "                window_length = int(window_length/4)\n",
    "            if window_length < 10:\n",
    "                loop = False\n",
    "            else:\n",
    "                loop = False\n",
    "        \n",
    "        if smooth is False:\n",
    "            if utm_coords:\n",
    "                cartesian_x = segy_pos_obj.cdp_x\n",
    "                cartesian_y = segy_pos_obj.cdp_y\n",
    "            else:\n",
    "                cartesian_x, cartesian_y = transformer.transform(segy_pos_obj.cdp_x, segy_pos_obj.cdp_y)\n",
    "            \n",
    "            segy_pos_obj.cdp_x_cartesian_smoothed = cartesian_x\n",
    "            segy_pos_obj.cdp_y_cartesian_smoothed = cartesian_y\n",
    "        \n",
    "        elif window_length < 10:\n",
    "            print(f'Can not smooth file {segy_pos_obj.name}')\n",
    "            \n",
    "            if utm_coords:\n",
    "                cartesian_x = segy_pos_obj.cdp_x\n",
    "                cartesian_y = segy_pos_obj.cdp_y\n",
    "            else:\n",
    "                cartesian_x, cartesian_y = transformer.transform(segy_pos_obj.cdp_x, segy_pos_obj.cdp_y)\n",
    "                \n",
    "            if '_not_smoothed' in segy_pos_obj.name:\n",
    "                pass\n",
    "            else:\n",
    "                segy_pos_obj.name = segy_pos_obj.name + '_not_smoothed'\n",
    "            \n",
    "            segy_pos_obj.cdp_x_cartesian_smoothed = cartesian_x\n",
    "            segy_pos_obj.cdp_y_cartesian_smoothed = cartesian_y\n",
    "        \n",
    "        else:\n",
    "            segy_pos_obj.cpd_x_smoothed = signal.savgol_filter(segy_pos_obj.cdp_x,window_length,3)\n",
    "            segy_pos_obj.cpd_y_smoothed = signal.savgol_filter(segy_pos_obj.cdp_y,window_length,3)\n",
    "            \n",
    "            if utm_coords:\n",
    "                cartesian_x = segy_pos_obj.cpd_x_smoothed\n",
    "                cartesian_y = segy_pos_obj.cpd_y_smoothed\n",
    "            else:\n",
    "                cartesian_x, cartesian_y = transformer.transform(segy_pos_obj.cpd_x_smoothed, segy_pos_obj.cpd_y_smoothed)\n",
    "        \n",
    "            segy_pos_obj.cdp_x_cartesian_smoothed = cartesian_x.tolist()\n",
    "            segy_pos_obj.cdp_y_cartesian_smoothed = cartesian_y.tolist()\n",
    "\n",
    "def save_track(pos_objs, save_to):\n",
    "    with open(save_to, 'w') as file2:\n",
    "        file2.write('num_o,num_i,name,datetime,traceno,cdp_x,cdp_y,year,day,hour,minute,second\\n')\n",
    "        num_o = 0\n",
    "        num_f = 0\n",
    "        \n",
    "        for segy_pos_obj in pos_objs:\n",
    "            \n",
    "            if '_rawpos' in segy_pos_obj.name:\n",
    "                name = segy_pos_obj.name[:-7]\n",
    "            else:\n",
    "                name = segy_pos_obj.name\n",
    "            \n",
    "            for num_i,traceno in enumerate(segy_pos_obj.traceno):\n",
    "                file2.write(f'{num_o},{num_i},{name},{segy_pos_obj.datetime[num_i]},{segy_pos_obj.traceno[num_i]},{segy_pos_obj.cdp_x_cartesian_smoothed[num_i]},')\n",
    "                file2.write(f'{segy_pos_obj.cdp_y_cartesian_smoothed[num_i]},{segy_pos_obj.year[num_i]},{segy_pos_obj.day[num_i]},{segy_pos_obj.hour[num_i]},{segy_pos_obj.minute[num_i]},')\n",
    "                file2.write(f'{segy_pos_obj.second[num_i]}\\n')\n",
    "                num_o += 1\n",
    "                \n",
    "            num_f += 1\n",
    "            print(f'File {segy_pos_obj.name} is done {num_f} of {len(pos_objs)}')\n",
    "            \n",
    "def save_track_to_radex(pos_objs):\n",
    "        \n",
    "    for pos_obj in pos_objs:\n",
    "        save_to = os.path.dirname(pos_obj.path)\n",
    "        \n",
    "        if '_rawpos' in pos_obj.name:\n",
    "            name = pos_obj.name[:-7]\n",
    "        else:\n",
    "            name = pos_obj.name\n",
    "    \n",
    "        with open(os.path.join(save_to, name + '_proc.txt'), 'w') as file3:\n",
    "            file3.write(f'TraceNo\\tCDPX\\tCDPY\\n')\n",
    "            for num, cdp_x in enumerate(pos_obj.cdp_x_cartesian_smoothed):\n",
    "                file3.write(f'{pos_obj.traceno[num]}\\t{pos_obj.cdp_x_cartesian_smoothed[num]}\\t{pos_obj.cdp_y_cartesian_smoothed[num]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.txt files in directory:F:\\SBP_DATA\\AI61\\AI-61_conv_BH\n",
      "74\n",
      "File AI61_20220630_185430_RAW_LF_rawpos is done 1 of 74\n",
      "File AI61_20220630_194920_RAW_LF_rawpos is done 2 of 74\n",
      "File AI61_20220630_205942_RAW_LF_rawpos is done 3 of 74\n",
      "File AI61_20220630_215657_RAW_LF_rawpos is done 4 of 74\n",
      "File AI61_20220630_225657_RAW_LF_rawpos is done 5 of 74\n",
      "File AI61_20220630_235657_RAW_LF_rawpos is done 6 of 74\n",
      "File AI61_20220701_000000_RAW_LF_rawpos is done 7 of 74\n",
      "File AI61_20220701_010000_RAW_LF_rawpos is done 8 of 74\n",
      "File AI61_20220701_020000_RAW_LF_rawpos is done 9 of 74\n",
      "File AI61_20220701_021420_RAW_LF_rawpos is done 10 of 74\n",
      "File AI61_20220701_031421_RAW_LF_rawpos is done 11 of 74\n",
      "File AI61_20220701_041421_RAW_LF_rawpos is done 12 of 74\n",
      "File AI61_20220701_051421_RAW_LF_rawpos is done 13 of 74\n",
      "File AI61_20220701_060421_RAW_LF_rawpos is done 14 of 74\n",
      "File AI61_20220701_070422_RAW_LF_rawpos is done 15 of 74\n",
      "File AI61_20220701_082424_RAW_LF_rawpos is done 16 of 74\n",
      "File AI61_20220701_090215_RAW_LF_rawpos is done 17 of 74\n",
      "File AI61_20220701_100216_RAW_LF_rawpos is done 18 of 74\n",
      "File AI61_20220701_114041_RAW_LF_rawpos is done 19 of 74\n",
      "File AI61_20220701_124041_RAW_LF_rawpos is done 20 of 74\n",
      "File AI61_20220701_135827_RAW_LF_rawpos is done 21 of 74\n",
      "File AI61_20220701_144811_RAW_LF_rawpos is done 22 of 74\n",
      "File AI61_20220701_161637_RAW_LF_rawpos is done 23 of 74\n",
      "File AI61_20220701_173629_RAW_LF_rawpos is done 24 of 74\n",
      "File AI61_20220701_185026_RAW_LF_rawpos is done 25 of 74\n",
      "File AI61_20220701_195913_RAW_LF_rawpos is done 26 of 74\n",
      "File AI61_20220701_201946_RAW_LF_rawpos is done 27 of 74\n",
      "File AI61_20220701_211946_RAW_LF_rawpos is done 28 of 74\n",
      "File AI61_20220701_221947_RAW_LF_rawpos is done 29 of 74\n",
      "File AI61_20220701_231625_RAW_LF_rawpos is done 30 of 74\n",
      "File AI61_20220702_000000_RAW_LF_rawpos is done 31 of 74\n",
      "File AI61_20220702_010000_RAW_LF_rawpos is done 32 of 74\n",
      "File AI61_20220702_015314_RAW_LF_rawpos is done 33 of 74\n",
      "File AI61_20220702_025314_RAW_LF_rawpos is done 34 of 74\n",
      "File AI61_20220702_035314_RAW_LF_rawpos is done 35 of 74\n",
      "File AI61_20220702_045315_RAW_LF_rawpos is done 36 of 74\n",
      "File AI61_20220702_050609_RAW_LF_rawpos is done 37 of 74\n",
      "File AI61_20220702_134828_RAW_LF_rawpos is done 38 of 74\n",
      "File AI61_20220702_144828_RAW_LF_rawpos is done 39 of 74\n",
      "File AI61_20220702_160627_RAW_LF_rawpos is done 40 of 74\n",
      "File AI61_20220702_170627_RAW_LF_rawpos is done 41 of 74\n",
      "File AI61_20220702_172931_RAW_LF_rawpos is done 42 of 74\n",
      "File AI61_20220702_173900_RAW_LF_rawpos is done 43 of 74\n",
      "File AI61_20220702_180734_RAW_LF_rawpos is done 44 of 74\n",
      "File AI61_20220702_190735_RAW_LF_rawpos is done 45 of 74\n",
      "File AI61_20220702_201429_RAW_LF_rawpos is done 46 of 74\n",
      "File AI61_20220702_211429_RAW_LF_rawpos is done 47 of 74\n",
      "File AI61_20220702_222112_RAW_LF_rawpos is done 48 of 74\n",
      "File AI61_20220702_232112_RAW_LF_rawpos is done 49 of 74\n",
      "File AI61_20220703_000000_RAW_LF_rawpos is done 50 of 74\n",
      "File AI61_20220703_010000_RAW_LF_rawpos is done 51 of 74\n",
      "File AI61_20220703_020000_RAW_LF_rawpos is done 52 of 74\n",
      "File AI61_20220703_021107_RAW_LF_rawpos is done 53 of 74\n",
      "File AI61_20220703_031108_RAW_LF_rawpos is done 54 of 74\n",
      "File AI61_20220703_041108_RAW_LF_rawpos is done 55 of 74\n",
      "File AI61_20220703_051108_RAW_LF_rawpos is done 56 of 74\n",
      "File AI61_20220703_061108_RAW_LF_rawpos is done 57 of 74\n",
      "File AI61_20220703_114712_RAW_LF_rawpos is done 58 of 74\n",
      "File AI61_20220703_131620_RAW_LF_rawpos is done 59 of 74\n",
      "File AI61_20220703_145911_RAW_LF_rawpos is done 60 of 74\n",
      "File AI61_20220703_155911_RAW_LF_rawpos is done 61 of 74\n",
      "File AI61_20220703_163759_RAW_LF_rawpos is done 62 of 74\n",
      "File AI61_20220703_181414_RAW_LF_rawpos is done 63 of 74\n",
      "File AI61_20220703_191414_RAW_LF_rawpos is done 64 of 74\n",
      "File AI61_20220703_201952_RAW_LF_rawpos is done 65 of 74\n",
      "File AI61_20220703_215127_RAW_LF_rawpos is done 66 of 74\n",
      "File AI61_20220703_232906_RAW_LF_rawpos is done 67 of 74\n",
      "File AI61_20220704_000000_RAW_LF_rawpos is done 68 of 74\n",
      "File AI61_20220704_010430_RAW_LF_rawpos is done 69 of 74\n",
      "File AI61_20220704_020430_RAW_LF_rawpos is done 70 of 74\n",
      "File AI61_20220704_023543_RAW_LF_rawpos is done 71 of 74\n",
      "File AI61_20220704_033543_RAW_LF_rawpos is done 72 of 74\n",
      "File AI61_20220704_040654_RAW_LF_rawpos is done 73 of 74\n",
      "File AI61_20220704_050654_RAW_LF_rawpos is done 74 of 74\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Proj, CRS, Transformer\n",
    "\n",
    "crs_wgs84 = CRS.from_epsg(4326)\n",
    "crs_utm35n = CRS.from_epsg(32635)\n",
    "crs_utm34n = CRS.from_epsg(32634)\n",
    "\n",
    "transformer = Transformer.from_crs(crs_wgs84, crs_utm34n, always_xy=True)\n",
    "\n",
    "data_path = r'F:\\SBP_DATA\\AI61\\AI-61_conv_BH'\n",
    "# track\n",
    "save_to = r'F:\\SBP_DATA\\\\AI61_BadHeave_SBP_WGS84UTM34N.txt'\n",
    "\n",
    "utm_coords = True\n",
    "year = 2022\n",
    "\n",
    "pos_files = fes.file_ext_search('.txt', data_path, recursive=False)\n",
    "print(len(pos_files))\n",
    "\n",
    "segy_pos_objs = []\n",
    "bad_data_dict = {}\n",
    "fine_data_dict = {}\n",
    "\n",
    "read_segypos(pos_files, fine_data_dict, bad_data_dict, segy_pos_objs, year, utm_coords = True)\n",
    "process_track(segy_pos_objs, transformer, window_length=25, smooth=False, utm_coords=True)\n",
    "save_track(segy_pos_objs, save_to)\n",
    "save_track_to_radex(segy_pos_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.sgy files in directory:D:\\SBP and Seismic\\abp49_SBP\\abp49_medu_taran_11\n",
      "file exists\n"
     ]
    }
   ],
   "source": [
    "# Replica\n",
    "has_header = False\n",
    "\n",
    "if os.path.exists(replica_path):\n",
    "    has_header = True\n",
    "    print('file exists')\n",
    "\n",
    "with open(replica_path, 'a') as file4:\n",
    "    if not has_header:\n",
    "        file4.write('prof_folder\\tfile_name\\tfile_name_proc\\tprof_name\\n')\n",
    "    \n",
    "    for sgy_file in sgy_files:\n",
    "        filename = os.path.splitext(os.path.basename(sgy_file))[0]\n",
    "        prof_folder = data_path\n",
    "        prof_name = os.path.split(data_path)[1]\n",
    "        filename_proc = filename + '_proc'\n",
    "        \n",
    "        file4.write(f'{prof_folder}\\t{filename}\\t{filename_proc}\\t{prof_name}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting files\n",
    "SLF_objs = []\n",
    "PHF_objs= []\n",
    "\n",
    "for segy_pos_obj in segy_pos_objs:\n",
    "    if 'SLF' in segy_pos_obj.name:\n",
    "        SLF_objs.append(segy_pos_obj)\n",
    "    elif 'PHF' in segy_pos_obj.name:\n",
    "        PHF_objs.append(segy_pos_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n"
     ]
    }
   ],
   "source": [
    "a = 'aaa_rawpos'\n",
    "\n",
    "\n",
    "if '_rawpos' in a:\n",
    "    print(a[:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
