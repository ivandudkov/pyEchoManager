{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, time, date\n",
    "from filemanager import file_ext_search as fes\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.txt files in directory:D:\\SBP and Seismic\\abp49_SBP\\abp49_medu_taran_11\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "data_path = r'D:\\SBP and Seismic\\abp49_SBP\\abp49_medu_taran_11'\n",
    "\n",
    "utm_coords = True\n",
    "year = 2022\n",
    "\n",
    "# track\n",
    "save_to = r'D:\\abp49_track111.txt'\n",
    "\n",
    "# replica\n",
    "replica_path = r'D:\\SBP and Seismic\\replica_3.txt'\n",
    "\n",
    "pos_files = fes.file_ext_search('.txt', data_path)\n",
    "print(len(pos_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-1_W2-SLF_ABP49_SLF2206061243_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061252_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061300_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061308_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061309_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061316_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061323_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061331_UTM-34_car\n",
      "test-1_W2-SLF_ABP49_SLF2206061338_UTM-34_car\n",
      "File test-1_W2-SLF_ABP49_SLF2206061243_UTM-34_car is done 1 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061252_UTM-34_car is done 2 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061300_UTM-34_car is done 3 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061308_UTM-34_car is done 4 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061309_UTM-34_car is done 5 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061316_UTM-34_car is done 6 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061323_UTM-34_car is done 7 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061331_UTM-34_car is done 8 of 9\n",
      "File test-1_W2-SLF_ABP49_SLF2206061338_UTM-34_car is done 9 of 9\n"
     ]
    }
   ],
   "source": [
    "# Reading raw pos\n",
    "@dataclass\n",
    "class SegyPosFile:\n",
    "    name: str\n",
    "    fin_traceno: int = 0\n",
    "    datetime: list = field(default_factory=list)\n",
    "    traceno: list = field(default_factory=list)\n",
    "    cdp_x: list = field(default_factory=list)\n",
    "    cdp_x_smoothed: list = field(default_factory=list)\n",
    "    cdp_y_smoothed: list = field(default_factory=list)\n",
    "    cdp_x_cartesian_smoothed: list = field(default_factory=list)\n",
    "    cdp_y_cartesian_smoothed: list = field(default_factory=list)\n",
    "    cdp_y: list = field(default_factory=list)\n",
    "    year: list = field(default_factory=list)\n",
    "    day: list = field(default_factory=list)\n",
    "    hour: list = field(default_factory=list)\n",
    "    minute: list = field(default_factory=list)\n",
    "    second: list = field(default_factory=list)\n",
    "\n",
    "segy_pos_objs = []\n",
    "bad_data_dict = {}\n",
    "fine_data_dict = {}\n",
    "\n",
    "\n",
    "for pos_file in pos_files:\n",
    "    segy_name = os.path.splitext(os.path.basename(pos_file))[0][:-7]\n",
    "    print(segy_name)\n",
    "    pos_obj = SegyPosFile(name=segy_name)\n",
    "    number = 0\n",
    "    \n",
    "    has_error = False\n",
    "    was_before = False\n",
    "    with open(pos_file, 'r') as file1:\n",
    "        file_content = file1.read().splitlines()\n",
    "        \n",
    "        for line in file_content[1:]:\n",
    "            line_content = line.split()\n",
    "\n",
    "            try:\n",
    "                \n",
    "                if utm_coords:\n",
    "                    if int(line_content[3]) != year:\n",
    "                        raise RuntimeError('BadYear')\n",
    "                    \n",
    "                    elif int(int(line_content[4])) > 370 and int(line_content[4]) < 0:\n",
    "                        raise RuntimeError('BadDay')\n",
    "                    \n",
    "                    elif float(line_content[1]) < 50000 and float(line_content[1]) > 500000:\n",
    "                        raise RuntimeError('BadCDP_X')\n",
    "                    \n",
    "                    elif float(line_content[2]) < 200000 and float(line_content[2]) > 8000000:\n",
    "                        raise RuntimeError('BadCDP_Y')\n",
    "\n",
    "                else:\n",
    "                    if int(line_content[3]) != year:\n",
    "                        raise RuntimeError('BadYear')\n",
    "                    \n",
    "                    elif int(int(line_content[4])) > 370 and int(line_content[4]) < 0:\n",
    "                        raise RuntimeError('BadDay')\n",
    "                    \n",
    "                    elif float(line_content[1]) < 15.0 and float(line_content[1]) > 50.0:\n",
    "                        raise RuntimeError('BadCDP_X')\n",
    "                    \n",
    "                    elif float(line_content[2]) < 30.0 and float(line_content[2]) > 70.0:\n",
    "                        raise RuntimeError('BadCDP_Y')\n",
    "                \n",
    "                ar = time(hour=int(line_content[5]),\n",
    "                        minute=int(line_content[6]), second=int(line_content[7]))\n",
    "            except:\n",
    "                number += 1\n",
    "                has_error = True\n",
    "                if not was_before:\n",
    "                    bad_data_dict['segy_name'] = pos_obj.traceno[-1]\n",
    "                    was_before = True\n",
    "                    \n",
    "            else:\n",
    "                pos_obj.datetime.append(f'{line_content[3]}-{line_content[4]}T{line_content[5]}:{line_content[6]}:{line_content[7]}')\n",
    "                pos_obj.traceno.append(int(line_content[0]))\n",
    "                pos_obj.cdp_x.append(float(line_content[1]))\n",
    "                pos_obj.cdp_y.append(float(line_content[2]))\n",
    "                pos_obj.year.append(int(line_content[3]))\n",
    "                pos_obj.day.append(int(line_content[4]))\n",
    "                pos_obj.hour.append(int(line_content[5]))\n",
    "                pos_obj.minute.append(int(line_content[6]))\n",
    "                pos_obj.second.append(int(line_content[7]))\n",
    "                \n",
    "        fine_data_dict[segy_name] = pos_obj.traceno[-1]\n",
    "        \n",
    "        if has_error:\n",
    "            print(f'Number of bad lines in {segy_name}: {number}')\n",
    "            \n",
    "        segy_pos_objs.append(pos_obj)\n",
    "\n",
    "# Sorting files\n",
    "SLF_objs = []\n",
    "PHF_objs= []\n",
    "\n",
    "for segy_pos_obj in segy_pos_objs:\n",
    "    if 'SLF' in segy_pos_obj.name:\n",
    "        SLF_objs.append(segy_pos_obj)\n",
    "    elif 'PHF' in segy_pos_obj.name:\n",
    "        PHF_objs.append(segy_pos_obj)\n",
    "\n",
    "# Track Processing\n",
    "from pyproj import Proj, CRS, Transformer\n",
    "\n",
    "crs_wgs84 = CRS.from_epsg(4326)\n",
    "# crs_utm35n = CRS.from_epsg(32635)\n",
    "crs_utm34n = CRS.from_epsg(32634)\n",
    "transformer = Transformer.from_crs(crs_wgs84, crs_utm34n, always_xy=True)\n",
    "\n",
    "with open(save_to, 'w') as file2:\n",
    "    file2.write('num_o,num_i,name,datetime,traceno,cdp_x,cdp_y,year,day,hour,minute,second\\n')\n",
    "    num_o = 0\n",
    "    num_f = 0\n",
    "    for segy_pos_obj in SLF_objs:\n",
    "        window_length = 201\n",
    "        file_length = len(segy_pos_obj.cdp_x)\n",
    "        \n",
    "        loop = True\n",
    "        while loop:\n",
    "            if window_length > file_length/4:\n",
    "                window_length = int(window_length/4)\n",
    "            elif window_length < 10:\n",
    "                loop = False\n",
    "            else:\n",
    "                loop = False\n",
    "        \n",
    "        if window_length < 10:\n",
    "            print(f'Can not smooth file {segy_pos_obj.name}')\n",
    "            \n",
    "            if utm_coords:\n",
    "                cartesian_x = segy_pos_obj.cdp_x\n",
    "                cartesian_y = segy_pos_obj.cdp_y\n",
    "            else:\n",
    "                cartesian_x, cartesian_y = transformer.transform(segy_pos_obj.cdp_x, segy_pos_obj.cdp_y)\n",
    "                \n",
    "            if '_not_smoothed' in segy_pos_obj.name:\n",
    "                pass\n",
    "            else:\n",
    "                segy_pos_obj.name = segy_pos_obj.name + '_not_smoothed'\n",
    "            \n",
    "            segy_pos_obj.cdp_x_cartesian_smoothed = cartesian_x\n",
    "            segy_pos_obj.cdp_y_cartesian_smoothed = cartesian_y\n",
    "        \n",
    "        else:\n",
    "            segy_pos_obj.cpd_x_smoothed = signal.savgol_filter(segy_pos_obj.cdp_x,window_length,3)\n",
    "            segy_pos_obj.cpd_y_smoothed = signal.savgol_filter(segy_pos_obj.cdp_y,window_length,3)\n",
    "            \n",
    "            if utm_coords:\n",
    "                cartesian_x = segy_pos_obj.cpd_x_smoothed\n",
    "                cartesian_y = segy_pos_obj.cpd_y_smoothed\n",
    "            else:\n",
    "                cartesian_x, cartesian_y = transformer.transform(segy_pos_obj.cpd_x_smoothed, segy_pos_obj.cpd_y_smoothed)\n",
    "        \n",
    "            segy_pos_obj.cdp_x_cartesian_smoothed = cartesian_x.tolist()\n",
    "            segy_pos_obj.cdp_y_cartesian_smoothed = cartesian_y.tolist()\n",
    "        \n",
    "        for num_i,traceno in enumerate(segy_pos_obj.traceno):\n",
    "            file2.write(f'{num_o},{num_i},{segy_pos_obj.name},{segy_pos_obj.datetime[num_i]},{segy_pos_obj.traceno[num_i]},{segy_pos_obj.cdp_x_cartesian_smoothed[num_i]},')\n",
    "            file2.write(f'{segy_pos_obj.cdp_y_cartesian_smoothed[num_i]},{segy_pos_obj.year[num_i]},{segy_pos_obj.day[num_i]},{segy_pos_obj.hour[num_i]},{segy_pos_obj.minute[num_i]},')\n",
    "            file2.write(f'{segy_pos_obj.second[num_i]}\\n')\n",
    "            num_o += 1\n",
    "        num_f += 1\n",
    "        print(f'File {segy_pos_obj.name} is done {num_f} of {len(segy_pos_objs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching *.sgy files in directory:D:\\SBP and Seismic\\abp49_SBP\\abp49_medu_taran_11\n",
      "file exists\n"
     ]
    }
   ],
   "source": [
    "# Replica\n",
    "sgy_files = fes.file_ext_search('.sgy', data_path)\n",
    "\n",
    "for sgy_file in sgy_files:\n",
    "    \n",
    "    filename = os.path.splitext(os.path.basename(sgy_file))[0]\n",
    "    \n",
    "    for slf_obj in SLF_objs:\n",
    "        if slf_obj.name == filename:\n",
    "            with open(os.path.join(data_path, filename + '_proc.txt'), 'w') as file3:\n",
    "                file3.write(f'TraceNo\\tCDPX\\tCDPY\\tBADTRACESTART\\n')\n",
    "                for num, cdp_x in enumerate(slf_obj.cdp_x_cartesian_smoothed):\n",
    "                    file3.write(f'{slf_obj.traceno[num]}\\t{slf_obj.cdp_x_cartesian_smoothed[num]}\\t{slf_obj.cdp_y_cartesian_smoothed[num]}\\n')\n",
    "\n",
    "has_header = False\n",
    "\n",
    "if os.path.exists(replica_path):\n",
    "    has_header = True\n",
    "    print('file exists')\n",
    "\n",
    "with open(replica_path, 'a') as file4:\n",
    "    if not has_header:\n",
    "        file4.write('prof_folder\\tfile_name\\tfile_name_proc\\tprof_name\\n')\n",
    "    \n",
    "    for sgy_file in sgy_files:\n",
    "        filename = os.path.splitext(os.path.basename(sgy_file))[0]\n",
    "        prof_folder = data_path\n",
    "        prof_name = os.path.split(data_path)[1]\n",
    "        filename_proc = filename + '_proc'\n",
    "        \n",
    "        file4.write(f'{prof_folder}\\t{filename}\\t{filename_proc}\\t{prof_name}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
